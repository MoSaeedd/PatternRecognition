{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusterProject.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFEtE49FtpL6eGa0r8A7an",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoSaeedd/PatternRecognition/blob/main/MusterProjectSimpleClassifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSDJnifGrp53",
        "outputId": "cf5eb6fb-9457-409a-9b97-6ae8cb570357"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import scipy.io\n",
        "# import numpy as np\n",
        "# from google.colab import drive\n",
        "# import pandas as pd\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# mat = scipy.io.loadmat('/content/drive/My Drive/RAS/Mustererkennung/Project/data.mat')\n",
        "# # print(mat)\n",
        "\n",
        "# labels = np.array(mat['train_label'])\n",
        "# train_data = np.array(mat['train_data'])\n",
        "# print(train_data.shape)\n",
        "# train_data = np.transpose(train_data.reshape(64*998,1728))\n",
        "\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     train_data, \n",
        "#     labels, \n",
        "#     test_size=0.2, \n",
        "#     random_state=69\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# print(train_data.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn import decomposition\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mat = scipy.io.loadmat('/content/drive/My Drive/RAS/Mustererkennung/Project/data.mat')\n",
        "# print(mat)\n",
        "\n",
        "labels = np.array(mat['train_label'])\n",
        "train_data = np.array(mat['train_data'])\n",
        "train_data = np.transpose(train_data.reshape(64*998,1728))\n",
        "# labels = np.repeat(labels,998)\n",
        "train_data = np.interp(train_data, (train_data.min(), train_data.max()), (-1, +1))\n",
        "\n",
        "\n",
        "pca = decomposition.PCA(n_components=120)\n",
        "train_data = pca.fit_transform(train_data)\n",
        "# pca.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_data, \n",
        "    labels, \n",
        "    test_size=0.15625, \n",
        "    random_state=69\n",
        ")\n",
        "# X_train_new = np.zeros([1458,50])\n",
        "# for i in range(0,X_train.shape[0]):\n",
        "#   xcurrent = X_train[i]\n",
        "#   xNew = np.zeros([64000,])\n",
        "#   xNew[0:64*998] = xcurrent\n",
        "#   xNew[64*998:] = np.mean(xNew)\n",
        "#   xNew = xNew.reshape(20,64*50)\n",
        "#   X_train_new[i*20:(i+1)*20,:] = xNew\n",
        "# y_train = np.repeat(y_train,20)\n",
        "# print(X_train_new.shape)\n",
        "\n",
        "\n",
        "# X_test_new = np.zeros([20*270,64*50])\n",
        "# for i in range(0,X_test.shape[0]):\n",
        "#   xcurrent = X_test[i]\n",
        "#   xNew = np.zeros([64000,])\n",
        "#   xNew[0:64*998] = xcurrent\n",
        "#   xNew[64*998:] = np.mean(xNew)\n",
        "#   xNew = xNew.reshape(20,64*50)\n",
        "#   X_test_new[i*20:(i+1)*20,:] = xNew\n",
        "# y_test = np.repeat(y_test,20)\n",
        "\n",
        "# X_test = X_test_new\n",
        "# X_train = X_train_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NckAcClxWO43",
        "outputId": "84bc886a-5d98-42a2-c4a3-1778a3745ed2"
      },
      "source": [
        "print(np.max(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "133.77201491590608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKxdPewYs5NI",
        "outputId": "53806f25-0510-43a8-9c9b-06d941175a5f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "####### Default Random Forest ########\n",
        "model = RandomForestClassifier(\n",
        "    random_state=69\n",
        ")\n",
        "tr_pd = pd.DataFrame(X_train) # make it pretty for display\n",
        "tr_pd.head()\n",
        "model.fit(X_train, y_train.ravel())\n",
        "\n",
        "print(f'Default Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "\n",
        "######### Tuned Random Forest #######\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators = 500, \n",
        "    criterion ='entropy',\n",
        "    warm_start = True,\n",
        "    max_features = 'sqrt',\n",
        "    oob_score = 'True', # more on this below\n",
        "    random_state=69  \n",
        ") \n",
        "\n",
        "model.fit(X_train, y_train.ravel())\n",
        "\n",
        "print(f'Modified Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Modified Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Random Forest Model's accuracy on training set is 100.00%\n",
            "Default Random Forest Model's accuracy on test set is 73.33%\n",
            "\n",
            "Modified Random Forest Model's accuracy on training set is 100.00%\n",
            "Modified Random Forest Model's accuracy on test set is 80.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEawFgLqw22x",
        "outputId": "97ec512e-5cc8-449c-82d8-3ef72aba951e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### (hastily) tuned kNN ######\n",
        "model = KNeighborsClassifier(\n",
        "    n_neighbors = 7,\n",
        "    weights = 'distance',\n",
        "    algorithm = 'brute',\n",
        "    leaf_size = '10',\n",
        "    n_jobs=4\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train.ravel())\n",
        "\n",
        "print(f'kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN Model's accuracy on training set is 100.00%\n",
            "kNN Model's accuracy on test set is 78.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X59c0xmf3tps",
        "outputId": "b8ca2a32-5ba8-42c3-aee3-9cd23f96d4fa"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Default 'off-the-shelf' MLP from sklearn\n",
        "model = MLPClassifier(\n",
        "    random_state = 69,\n",
        "    hidden_layer_sizes = (320,400),\n",
        "    activation = 'relu',\n",
        "    solver = 'adam',\n",
        "    alpha = 0.001,\n",
        "    epsilon = 0.001 ,\n",
        "    learning_rate = 'adaptive'\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train.ravel())\n",
        "\n",
        "print(f'Possible classes predicted by model:{model.classes_}')\n",
        "print(f'Unscaled MLP Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Unscaled MLP Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible classes predicted by model:[1. 2. 3. 4.]\n",
            "Unscaled MLP Model's accuracy on training set is 100.00%\n",
            "Unscaled MLP Model's accuracy on test set is 88.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUpQju36G36m",
        "outputId": "ab933e56-3c72-443d-e0da-ed5a0393f932"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(\n",
        "    C=10,\n",
        "    gamma='auto',\n",
        "    kernel='rbf',\n",
        "    tol = 0.001,\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'SVC Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'SVC Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC Model's accuracy on training set is 100.00%\n",
            "SVC Model's accuracy on test set is 71.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BwEBkfj4SIY",
        "outputId": "280afa09-0e2a-48fb-8aff-a73d79cebc69"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize the MLP Classifier and choose parameters we want to keep constant\n",
        "model = MLPClassifier(\n",
        "    # tune batch size later \n",
        "    batch_size=256,  \n",
        "    # keep random state constant to accurately compare subsequent models\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "# Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
        "parameter_space = {\n",
        "    # A single hidden layer of size between 8 (output classes) and 180 (input features) neurons is most probable\n",
        "    # It's a bad idea at guessing the number of hidden layers to have\n",
        "    # ...but we'll give 2 and 3 hidden layers a shot to reaffirm our suspicions that 1 is best\n",
        "    'hidden_layer_sizes': [(8,),(400,),(500,120,40,),(80,30,)], \n",
        "    'activation': ['tanh','relu', 'logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001,0.001,0.01],\n",
        "    'epsilon': [ 0.0001,0.001,0.01],\n",
        "    'learning_rate': ['adaptive', 'constant']\n",
        "}\n",
        "   \n",
        "# Create a grid search object which will store the scores and hyperparameters of all candidate models \n",
        "grid = GridSearchCV(\n",
        "    model, \n",
        "    parameter_space,\n",
        "    cv=10,\n",
        "    n_jobs=-5)\n",
        "# Fit the models specified by the parameter grid \n",
        "grid.fit(X_train, y_train.ravel())\n",
        "\n",
        "# get the best hyperparameters from grid search object with its best_params_ attribute\n",
        "print('Best parameters found:\\n', grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS2ErN9948bP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}